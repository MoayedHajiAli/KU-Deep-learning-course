{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading trainging and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages\n",
    "using Pkg\n",
    "haskey(Pkg.installed(),\"Knet\") || Pkg.add(\"Knet\")\n",
    "haskey(Pkg.installed(),\"CodecZlib\") || Pkg.add(\"CodecZlib\")\n",
    "haskey(Pkg.installed(),\"Images\") || Pkg.add(\"Images\")\n",
    "haskey(Pkg.installed(), \"Colors\") || Pkg.add(\"Colors\")\n",
    "haskey(Pkg.installed(), \"Statistics\") || Pkg.add(\"Statistics\")\n",
    "haskey(Pkg.installed(), \"Random\") || Pkg.add(\"Random\")\n",
    "using Knet\n",
    "using CodecZlib\n",
    "using Plots, Statistics, LinearAlgebra, Random\n",
    "using Images, ImageIO, QuartzImageIO, ImageMagick, Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading train-images-idx3-ubyte.gz\n",
      "downloading train-labels-idx1-ubyte.gz\n",
      "downloading t10k-images-idx3-ubyte.gz\n",
      "downloading t10k-labels-idx1-ubyte.gz\n",
      "60008 10008\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# the data will be imported from \"http://yann.lecun.com/exdb/mnist\"\n",
    "mnsitUrl = \"http://yann.lecun.com/exdb/mnist\"\n",
    "mnsitDir = \"./Data\"\n",
    "xtrn_file, ytrn_file, xtst_file, ytst_file = \n",
    "    \"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\", \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "\n",
    "#download the traing and testing files\n",
    "function _mnsit_download_data(file)\n",
    "    println(\"downloading $file\")\n",
    "    if(!isdir(mnsitDir))\n",
    "        mkpath(mnsitDir)\n",
    "    end\n",
    "    filePath = joinpath(mnsitDir, file)\n",
    "    if(!isfile(filePath))\n",
    "        url = string(mnsitUrl, \"/\", file)\n",
    "        println(url)\n",
    "        download(url, filePath)\n",
    "    end\n",
    "    \n",
    "    #each images x file conatins the images represented as 784 pixels, which are normalized to [0-1] float numbers\n",
    "    #each label y is represented as a single number which represents the correct digit. 10 is used to represnt 0\n",
    "    f = GzipDecompressorStream(open(filePath))\n",
    "    a = read(f)\n",
    "    close(f)\n",
    "    return(a)\n",
    "end\n",
    "\n",
    "\n",
    "function _mnsit_load_data()\n",
    "    global xtrn, ytrn, xtst, ytst\n",
    "    xtrn, ytrn, xtst, ytst = _mnsit_download_data.([xtrn_file, ytrn_file, xtst_file, ytst_file])\n",
    "    #reshape y data to an array of dimantions 28*28*1*N, where N is the number of samples\n",
    "    _x_reshape(x) = reshape(x[17:end] ./ 255f0, (28,28,1,(length(x)÷(28*28))))\n",
    "    xtrn, xtst = _x_reshape.([xtrn, xtst])\n",
    "    println(length(ytrn), \" \" , length(ytst))\n",
    "    _y_reshape(y) = (Int.(y);(y[y.==0] .= 10); y[9:end])\n",
    "    ytrn, ytst = _y_reshape.([ytrn, ytst])\n",
    "    println(length(ytrn), \" \" , length(ytst))\n",
    "end\n",
    "\n",
    "_mnsit_load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show couple of samples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×28 Array{Gray{Float32},2} with eltype Gray{Float32}:\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱                    \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct digit is: 8\n"
     ]
    }
   ],
   "source": [
    "ind = rand(1:size(xtrn, 4))\n",
    "img = xtrn[:,:,1,ind]\n",
    "println(\"The correct digit is: \", ytrn[ind])\n",
    "Image = Gray.(img)\n",
    "display(Image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data and essential functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting y data to one hot represntation\n",
    "function one_hot(y)\n",
    "    tmp = zeros(10,length(y))\n",
    "    for i in 1:length(y)\n",
    "        tmp[y[i], i] = 1\n",
    "    end\n",
    "    return tmp\n",
    "end\n",
    "ytrn, ytst = one_hot.([ytrn, ytst])\n",
    "#converting x data into 784*N matrix\n",
    "xtrn = Array{Float32}(mat(xtrn))\n",
    "xtst = Array{Float32}(mat(xtst))\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784×60000 Array{Float32,2}\n",
      "10×60000 Array{Float64,2}\n",
      "784×10000 Array{Float32,2}\n",
      "10×10000 Array{Float64,2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println.(summary.((xtrn, ytrn, xtst, ytst)))\n",
    "#divid the data into minibatches\n",
    "dtrn = minibatch(xtrn,ytrn,100)\n",
    "dtst = minibatch(xtst,ytst,100)\n",
    "#define accuracy\n",
    "function accuracy(w, data)\n",
    "    mean = 0\n",
    "    for (x,y) in data\n",
    "        for i in size(y, 2)\n",
    "            mean += argmax(w*x[:,i]) == argmax(y[:,i])\n",
    "        end\n",
    "    end\n",
    "    return mean/length(data)\n",
    "end\n",
    "#define W, our predection parameters\n",
    "w = rand(Float32, (10, 784))\n",
    "#accuracy test with random parameters\n",
    "accuracy(w, dtst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large VS Small batch-size training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: unexpected \"end\"",
     "output_type": "error",
     "traceback": [
      "syntax: unexpected \"end\"",
      ""
     ]
    }
   ],
   "source": [
    "#trainging using large batch size (100)\n",
    "function train(f, data, iter)\n",
    "    w = rand(Float32, (10, 784))\n",
    "    println(length(data))\n",
    "    for i in 1:iter\n",
    "        for (x,y) in data\n",
    "            f(w,x,y)\n",
    "        end\n",
    "        println(\"iteration $i has an accuracy in the dtst of $(accuracy(w,dtst))\", \" \", norm(w))\n",
    "        println(\"iteration $i has an accuracy in the dtrn of $(accuracy(w,dtrn))\", \" \", norm(w))\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 2 methods)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainging using small batch size (1)\n",
    "function train(f, xtrn::Array, ytrn::Array, iter)\n",
    "    w = rand(Float32, (10, 784))\n",
    "    for i in 1:(1<<iter)\n",
    "        last = rand(1:size(xtrn,2))\n",
    "        xx,yy = xtrn[:,last:last], ytrn[:,last:last]\n",
    "        f(w,xx,yy)\n",
    "        if log2(i) ≈ round(log2(i))\n",
    "            println(\"iteration $i has an accuracy in the dtst of $(accuracy(w,dtst))\", \" \", norm(w))\n",
    "            println(\"iteration $i has an accuracy in the dtrn of $(accuracy(w,dtrn))\", \" \", norm(w))\n",
    "        end\n",
    "    end\n",
    "    println(\"iteration (1<<iter) has an accuracy in the dtst of $(accuracy(w,dtst))\", \" \", norm(w))\n",
    "    println(\"iteration (1<<iter) has an accuracy in the dtrn of $(accuracy(w,dtrn))\", \" \", norm(w))\n",
    "    return w\n",
    "end\n",
    "#=note that will larger batch size we achieve higher accuracy on the training dataset, but lower accurcy in the testing\n",
    "dataset, and vica versa with lower batch size=#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perceptron (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function perceptron(w,x,y)\n",
    "    pred = w*x\n",
    "    for i in size(y,2)\n",
    "        guess = argmax(pred[:,i])\n",
    "        class = argmax(y[:,i])\n",
    "        if guess != class\n",
    "            w[guess,:] -= x[:,i]\n",
    "            w[class,:] += x[:,i]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One layer Perceptron with batch size of 100\n",
      "iteration 1 has an accuracy in the dtst of 0.05 51.296436\n",
      "iteration 1 has an accuracy in the dtrn of 0.07166666666666667 51.296436\n",
      "iteration 2 has an accuracy in the dtst of 0.13 52.703884\n",
      "iteration 2 has an accuracy in the dtrn of 0.10666666666666667 52.703884\n",
      "iteration 4 has an accuracy in the dtst of 0.13 53.909817\n",
      "iteration 4 has an accuracy in the dtrn of 0.09333333333333334 53.909817\n",
      "iteration 8 has an accuracy in the dtst of 0.12 56.78446\n",
      "iteration 8 has an accuracy in the dtrn of 0.09833333333333333 56.78446\n",
      "iteration 16 has an accuracy in the dtst of 0.2 62.41667\n",
      "iteration 16 has an accuracy in the dtrn of 0.13833333333333334 62.41667\n",
      "iteration 32 has an accuracy in the dtst of 0.26 73.34317\n",
      "iteration 32 has an accuracy in the dtrn of 0.2916666666666667 73.34317\n",
      "iteration 64 has an accuracy in the dtst of 0.52 88.03698\n",
      "iteration 64 has an accuracy in the dtrn of 0.3983333333333333 88.03698\n",
      "iteration 128 has an accuracy in the dtst of 0.6 100.054596\n",
      "iteration 128 has an accuracy in the dtrn of 0.5116666666666667 100.054596\n",
      "iteration 256 has an accuracy in the dtst of 0.63 121.81841\n",
      "iteration 256 has an accuracy in the dtrn of 0.5366666666666666 121.81841\n",
      "iteration 512 has an accuracy in the dtst of 0.72 154.31203\n",
      "iteration 512 has an accuracy in the dtrn of 0.7433333333333333 154.31203\n",
      "iteration 1024 has an accuracy in the dtst of 0.85 192.09265\n",
      "iteration 1024 has an accuracy in the dtrn of 0.7866666666666666 192.09265\n",
      "iteration 2048 has an accuracy in the dtst of 0.84 231.4821\n",
      "iteration 2048 has an accuracy in the dtrn of 0.8083333333333333 231.4821\n",
      "iteration 4096 has an accuracy in the dtst of 0.9 285.54364\n",
      "iteration 4096 has an accuracy in the dtrn of 0.8616666666666667 285.54364\n",
      "iteration 8192 has an accuracy in the dtst of 0.82 343.63373\n",
      "iteration 8192 has an accuracy in the dtrn of 0.865 343.63373\n",
      "iteration 16384 has an accuracy in the dtst of 0.91 405.29434\n",
      "iteration 16384 has an accuracy in the dtrn of 0.8966666666666666 405.29434\n",
      "iteration 32768 has an accuracy in the dtst of 0.92 487.79074\n",
      "iteration 32768 has an accuracy in the dtrn of 0.8883333333333333 487.79074\n",
      "iteration 65536 has an accuracy in the dtst of 0.93 589.5446\n",
      "iteration 65536 has an accuracy in the dtrn of 0.89 589.5446\n",
      "iteration 131072 has an accuracy in the dtst of 0.91 717.60034\n",
      "iteration 131072 has an accuracy in the dtrn of 0.8933333333333333 717.60034\n",
      "iteration 262144 has an accuracy in the dtst of 0.89 867.69684\n",
      "iteration 262144 has an accuracy in the dtrn of 0.9 867.69684\n",
      "iteration 524288 has an accuracy in the dtst of 0.9 1064.779\n",
      "iteration 524288 has an accuracy in the dtrn of 0.925 1064.779\n",
      "iteration 1048576 has an accuracy in the dtst of 0.92 1335.1624\n",
      "iteration 1048576 has an accuracy in the dtrn of 0.9166666666666666 1335.1624\n",
      "iteration (1<<iter) has an accuracy in the dtst of 0.92 1335.1624\n",
      "iteration (1<<iter) has an accuracy in the dtrn of 0.9166666666666666 1335.1624\n",
      "One layer Perceptron with batch size of 1\n",
      "600\n",
      "iteration 1 has an accuracy in the dtst of 0.6 159.67967\n",
      "iteration 1 has an accuracy in the dtrn of 0.6733333333333333 159.67967\n",
      "iteration 2 has an accuracy in the dtst of 0.74 187.04587\n",
      "iteration 2 has an accuracy in the dtrn of 0.83 187.04587\n",
      "iteration 3 has an accuracy in the dtst of 0.73 207.01825\n",
      "iteration 3 has an accuracy in the dtrn of 0.8716666666666667 207.01825\n",
      "iteration 4 has an accuracy in the dtst of 0.79 225.26123\n",
      "iteration 4 has an accuracy in the dtrn of 0.9166666666666666 225.26123\n",
      "iteration 5 has an accuracy in the dtst of 0.68 241.4797\n",
      "iteration 5 has an accuracy in the dtrn of 0.85 241.4797\n",
      "iteration 6 has an accuracy in the dtst of 0.72 250.28824\n",
      "iteration 6 has an accuracy in the dtrn of 0.8516666666666667 250.28824\n",
      "iteration 7 has an accuracy in the dtst of 0.76 257.89163\n",
      "iteration 7 has an accuracy in the dtrn of 0.9666666666666667 257.89163\n",
      "iteration 8 has an accuracy in the dtst of 0.77 264.25574\n",
      "iteration 8 has an accuracy in the dtrn of 0.9733333333333334 264.25574\n",
      "iteration 9 has an accuracy in the dtst of 0.8 267.08588\n",
      "iteration 9 has an accuracy in the dtrn of 0.995 267.08588\n",
      "iteration 10 has an accuracy in the dtst of 0.8 269.5457\n",
      "iteration 10 has an accuracy in the dtrn of 0.9833333333333333 269.5457\n",
      "iteration 11 has an accuracy in the dtst of 0.78 273.14087\n",
      "iteration 11 has an accuracy in the dtrn of 0.9816666666666667 273.14087\n",
      "iteration 12 has an accuracy in the dtst of 0.71 277.65692\n",
      "iteration 12 has an accuracy in the dtrn of 0.9716666666666667 277.65692\n",
      "iteration 13 has an accuracy in the dtst of 0.82 283.27155\n",
      "iteration 13 has an accuracy in the dtrn of 0.995 283.27155\n",
      "iteration 14 has an accuracy in the dtst of 0.78 285.8124\n",
      "iteration 14 has an accuracy in the dtrn of 0.99 285.8124\n",
      "iteration 15 has an accuracy in the dtst of 0.77 289.56146\n",
      "iteration 15 has an accuracy in the dtrn of 0.97 289.56146\n",
      "iteration 16 has an accuracy in the dtst of 0.82 291.06268\n",
      "iteration 16 has an accuracy in the dtrn of 0.9983333333333333 291.06268\n",
      "iteration 17 has an accuracy in the dtst of 0.8 293.24576\n",
      "iteration 17 has an accuracy in the dtrn of 0.9966666666666667 293.24576\n",
      "iteration 18 has an accuracy in the dtst of 0.77 294.20514\n",
      "iteration 18 has an accuracy in the dtrn of 0.995 294.20514\n",
      "iteration 19 has an accuracy in the dtst of 0.79 295.74573\n",
      "iteration 19 has an accuracy in the dtrn of 0.9983333333333333 295.74573\n",
      "iteration 20 has an accuracy in the dtst of 0.79 296.3621\n",
      "iteration 20 has an accuracy in the dtrn of 0.9983333333333333 296.3621\n",
      "iteration 21 has an accuracy in the dtst of 0.81 297.7228\n",
      "iteration 21 has an accuracy in the dtrn of 0.9766666666666667 297.7228\n",
      "iteration 22 has an accuracy in the dtst of 0.82 301.11618\n",
      "iteration 22 has an accuracy in the dtrn of 0.9833333333333333 301.11618\n",
      "iteration 23 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 23 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 24 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 24 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 25 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 25 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 26 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 26 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 27 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 27 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 28 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 28 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 29 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 29 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 30 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 30 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 31 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 31 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 32 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 32 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 33 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 33 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 34 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 34 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 35 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 35 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 36 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 36 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 37 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 37 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 38 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 38 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 39 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 39 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 40 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 40 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 41 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 41 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 42 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 42 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 43 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 43 has an accuracy in the dtrn of 1.0 301.78217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 44 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 44 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 45 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 45 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 46 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 46 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 47 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 47 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 48 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 48 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 49 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 49 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 50 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 50 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 51 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 51 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 52 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 52 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 53 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 53 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 54 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 54 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 55 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 55 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 56 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 56 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 57 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 57 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 58 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 58 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 59 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 59 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 60 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 60 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 61 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 61 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 62 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 62 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 63 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 63 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 64 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 64 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 65 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 65 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 66 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 66 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 67 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 67 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 68 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 68 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 69 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 69 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 70 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 70 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 71 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 71 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 72 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 72 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 73 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 73 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 74 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 74 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 75 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 75 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 76 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 76 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 77 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 77 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 78 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 78 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 79 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 79 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 80 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 80 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 81 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 81 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 82 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 82 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 83 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 83 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 84 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 84 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 85 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 85 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 86 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 86 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 87 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 87 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 88 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 88 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 89 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 89 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 90 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 90 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 91 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 91 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 92 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 92 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 93 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 93 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 94 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 94 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 95 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 95 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 96 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 96 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 97 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 97 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 98 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 98 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 99 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 99 has an accuracy in the dtrn of 1.0 301.78217\n",
      "iteration 100 has an accuracy in the dtst of 0.78 301.78217\n",
      "iteration 100 has an accuracy in the dtrn of 1.0 301.78217\n"
     ]
    }
   ],
   "source": [
    "println(\"One layer Perceptron with batch size of 100\")\n",
    "wperceptron_1 = train(perceptron, xtrn, ytrn, 20)\n",
    "println(\"One layer Perceptron with batch size of 1\")\n",
    "wperceptron_100 = train(perceptron, dtrn, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adaline (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function adaline(w, x, y; lr = 1e-4)\n",
    "    err = w * x - y\n",
    "    w .-= lr * err * x'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaline with batch size of 100\n",
      "iteration 1 has an accuracy in the dtst of 0.06 51.20988\n",
      "iteration 1 has an accuracy in the dtrn of 0.09666666666666666 51.20988\n",
      "iteration 2 has an accuracy in the dtst of 0.06 51.178806\n",
      "iteration 2 has an accuracy in the dtrn of 0.09666666666666666 51.178806\n",
      "iteration 4 has an accuracy in the dtst of 0.06 50.9792\n",
      "iteration 4 has an accuracy in the dtrn of 0.09666666666666666 50.9792\n",
      "iteration 8 has an accuracy in the dtst of 0.05 50.772324\n",
      "iteration 8 has an accuracy in the dtrn of 0.09833333333333333 50.772324\n",
      "iteration 16 has an accuracy in the dtst of 0.06 50.411865\n",
      "iteration 16 has an accuracy in the dtrn of 0.1 50.411865\n",
      "iteration 32 has an accuracy in the dtst of 0.06 49.636353\n",
      "iteration 32 has an accuracy in the dtrn of 0.10166666666666667 49.636353\n",
      "iteration 64 has an accuracy in the dtst of 0.06 48.28393\n",
      "iteration 64 has an accuracy in the dtrn of 0.10333333333333333 48.28393\n",
      "iteration 128 has an accuracy in the dtst of 0.06 46.380688\n",
      "iteration 128 has an accuracy in the dtrn of 0.11 46.380688\n",
      "iteration 256 has an accuracy in the dtst of 0.05 44.334877\n",
      "iteration 256 has an accuracy in the dtrn of 0.10833333333333334 44.334877\n",
      "iteration 512 has an accuracy in the dtst of 0.06 42.970013\n",
      "iteration 512 has an accuracy in the dtrn of 0.1 42.970013\n",
      "iteration 1024 has an accuracy in the dtst of 0.07 42.414726\n",
      "iteration 1024 has an accuracy in the dtrn of 0.09333333333333334 42.414726\n",
      "iteration 2048 has an accuracy in the dtst of 0.08 41.88922\n",
      "iteration 2048 has an accuracy in the dtrn of 0.10333333333333333 41.88922\n",
      "iteration 4096 has an accuracy in the dtst of 0.14 41.236897\n",
      "iteration 4096 has an accuracy in the dtrn of 0.11833333333333333 41.236897\n",
      "iteration 8192 has an accuracy in the dtst of 0.16 40.519814\n",
      "iteration 8192 has an accuracy in the dtrn of 0.15833333333333333 40.519814\n",
      "iteration 16384 has an accuracy in the dtst of 0.2 39.68183\n",
      "iteration 16384 has an accuracy in the dtrn of 0.23 39.68183\n",
      "iteration 32768 has an accuracy in the dtst of 0.21 38.661015\n",
      "iteration 32768 has an accuracy in the dtrn of 0.28 38.661015\n",
      "iteration 65536 has an accuracy in the dtst of 0.26 37.396255\n",
      "iteration 65536 has an accuracy in the dtrn of 0.3233333333333333 37.396255\n",
      "iteration 131072 has an accuracy in the dtst of 0.4 35.875767\n",
      "iteration 131072 has an accuracy in the dtrn of 0.395 35.875767\n",
      "iteration 262144 has an accuracy in the dtst of 0.46 34.105476\n",
      "iteration 262144 has an accuracy in the dtrn of 0.49166666666666664 34.105476\n",
      "iteration 524288 has an accuracy in the dtst of 0.56 32.174503\n",
      "iteration 524288 has an accuracy in the dtrn of 0.6016666666666667 32.174503\n",
      "iteration 1048576 has an accuracy in the dtst of 0.82 30.278595\n",
      "iteration 1048576 has an accuracy in the dtrn of 0.7366666666666667 30.278595\n",
      "iteration (1<<iter) has an accuracy in the dtst of 0.82 30.278595\n",
      "iteration (1<<iter) has an accuracy in the dtrn of 0.7366666666666667 30.278595\n",
      "Adaline with batch size of 1\n",
      "600\n",
      "iteration 1 has an accuracy in the dtst of 0.32 37.773922\n",
      "iteration 1 has an accuracy in the dtrn of 0.33 37.773922\n",
      "iteration 2 has an accuracy in the dtst of 0.42 36.24784\n",
      "iteration 2 has an accuracy in the dtrn of 0.41333333333333333 36.24784\n",
      "iteration 3 has an accuracy in the dtst of 0.5 35.22507\n",
      "iteration 3 has an accuracy in the dtrn of 0.475 35.22507\n",
      "iteration 4 has an accuracy in the dtst of 0.53 34.45098\n",
      "iteration 4 has an accuracy in the dtrn of 0.49833333333333335 34.45098\n",
      "iteration 5 has an accuracy in the dtst of 0.58 33.82981\n",
      "iteration 5 has an accuracy in the dtrn of 0.5266666666666666 33.82981\n",
      "iteration 6 has an accuracy in the dtst of 0.6 33.313293\n",
      "iteration 6 has an accuracy in the dtrn of 0.555 33.313293\n",
      "iteration 7 has an accuracy in the dtst of 0.64 32.873055\n",
      "iteration 7 has an accuracy in the dtrn of 0.5883333333333334 32.873055\n",
      "iteration 8 has an accuracy in the dtst of 0.67 32.49081\n",
      "iteration 8 has an accuracy in the dtrn of 0.6133333333333333 32.49081\n",
      "iteration 9 has an accuracy in the dtst of 0.69 32.154034\n",
      "iteration 9 has an accuracy in the dtrn of 0.635 32.154034\n",
      "iteration 10 has an accuracy in the dtst of 0.7 31.853756\n",
      "iteration 10 has an accuracy in the dtrn of 0.655 31.853756\n",
      "iteration 11 has an accuracy in the dtst of 0.71 31.583344\n",
      "iteration 11 has an accuracy in the dtrn of 0.6783333333333333 31.583344\n",
      "iteration 12 has an accuracy in the dtst of 0.71 31.337765\n",
      "iteration 12 has an accuracy in the dtrn of 0.6983333333333334 31.337765\n",
      "iteration 13 has an accuracy in the dtst of 0.71 31.113121\n",
      "iteration 13 has an accuracy in the dtrn of 0.71 31.113121\n",
      "iteration 14 has an accuracy in the dtst of 0.74 30.906334\n",
      "iteration 14 has an accuracy in the dtrn of 0.7183333333333334 30.906334\n",
      "iteration 15 has an accuracy in the dtst of 0.75 30.714937\n",
      "iteration 15 has an accuracy in the dtrn of 0.7333333333333333 30.714937\n",
      "iteration 16 has an accuracy in the dtst of 0.76 30.536928\n",
      "iteration 16 has an accuracy in the dtrn of 0.745 30.536928\n",
      "iteration 17 has an accuracy in the dtst of 0.79 30.370657\n",
      "iteration 17 has an accuracy in the dtrn of 0.7533333333333333 30.370657\n",
      "iteration 18 has an accuracy in the dtst of 0.79 30.214758\n",
      "iteration 18 has an accuracy in the dtrn of 0.7583333333333333 30.214758\n",
      "iteration 19 has an accuracy in the dtst of 0.82 30.06808\n",
      "iteration 19 has an accuracy in the dtrn of 0.7783333333333333 30.06808\n",
      "iteration 20 has an accuracy in the dtst of 0.82 29.929653\n",
      "iteration 20 has an accuracy in the dtrn of 0.7816666666666666 29.929653\n",
      "iteration 21 has an accuracy in the dtst of 0.82 29.798649\n",
      "iteration 21 has an accuracy in the dtrn of 0.7833333333333333 29.798649\n",
      "iteration 22 has an accuracy in the dtst of 0.82 29.67435\n",
      "iteration 22 has an accuracy in the dtrn of 0.7833333333333333 29.67435\n",
      "iteration 23 has an accuracy in the dtst of 0.83 29.556147\n",
      "iteration 23 has an accuracy in the dtrn of 0.795 29.556147\n",
      "iteration 24 has an accuracy in the dtst of 0.84 29.443495\n",
      "iteration 24 has an accuracy in the dtrn of 0.8 29.443495\n",
      "iteration 25 has an accuracy in the dtst of 0.85 29.33593\n",
      "iteration 25 has an accuracy in the dtrn of 0.8083333333333333 29.33593\n",
      "iteration 26 has an accuracy in the dtst of 0.86 29.233034\n",
      "iteration 26 has an accuracy in the dtrn of 0.8133333333333334 29.233034\n",
      "iteration 27 has an accuracy in the dtst of 0.86 29.134445\n",
      "iteration 27 has an accuracy in the dtrn of 0.815 29.134445\n",
      "iteration 28 has an accuracy in the dtst of 0.86 29.039837\n",
      "iteration 28 has an accuracy in the dtrn of 0.82 29.039837\n",
      "iteration 29 has an accuracy in the dtst of 0.85 28.94892\n",
      "iteration 29 has an accuracy in the dtrn of 0.82 28.94892\n",
      "iteration 30 has an accuracy in the dtst of 0.86 28.861431\n",
      "iteration 30 has an accuracy in the dtrn of 0.82 28.861431\n",
      "iteration 31 has an accuracy in the dtst of 0.86 28.77714\n",
      "iteration 31 has an accuracy in the dtrn of 0.825 28.77714\n",
      "iteration 32 has an accuracy in the dtst of 0.86 28.695833\n",
      "iteration 32 has an accuracy in the dtrn of 0.8266666666666667 28.695833\n",
      "iteration 33 has an accuracy in the dtst of 0.85 28.617323\n",
      "iteration 33 has an accuracy in the dtrn of 0.8333333333333334 28.617323\n",
      "iteration 34 has an accuracy in the dtst of 0.85 28.541435\n",
      "iteration 34 has an accuracy in the dtrn of 0.8316666666666667 28.541435\n",
      "iteration 35 has an accuracy in the dtst of 0.85 28.46801\n",
      "iteration 35 has an accuracy in the dtrn of 0.8333333333333334 28.46801\n",
      "iteration 36 has an accuracy in the dtst of 0.85 28.396904\n",
      "iteration 36 has an accuracy in the dtrn of 0.8333333333333334 28.396904\n",
      "iteration 37 has an accuracy in the dtst of 0.85 28.327986\n",
      "iteration 37 has an accuracy in the dtrn of 0.835 28.327986\n",
      "iteration 38 has an accuracy in the dtst of 0.85 28.261133\n",
      "iteration 38 has an accuracy in the dtrn of 0.8333333333333334 28.261133\n",
      "iteration 39 has an accuracy in the dtst of 0.85 28.196236\n",
      "iteration 39 has an accuracy in the dtrn of 0.8333333333333334 28.196236\n",
      "iteration 40 has an accuracy in the dtst of 0.85 28.133188\n",
      "iteration 40 has an accuracy in the dtrn of 0.835 28.133188\n",
      "iteration 41 has an accuracy in the dtst of 0.85 28.071898\n",
      "iteration 41 has an accuracy in the dtrn of 0.8383333333333334 28.071898\n",
      "iteration 42 has an accuracy in the dtst of 0.85 28.012276\n",
      "iteration 42 has an accuracy in the dtrn of 0.8383333333333334 28.012276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 43 has an accuracy in the dtst of 0.84 27.95424\n",
      "iteration 43 has an accuracy in the dtrn of 0.84 27.95424\n",
      "iteration 44 has an accuracy in the dtst of 0.84 27.897715\n",
      "iteration 44 has an accuracy in the dtrn of 0.8433333333333334 27.897715\n",
      "iteration 45 has an accuracy in the dtst of 0.84 27.84263\n",
      "iteration 45 has an accuracy in the dtrn of 0.8433333333333334 27.84263\n",
      "iteration 46 has an accuracy in the dtst of 0.84 27.788918\n",
      "iteration 46 has an accuracy in the dtrn of 0.8466666666666667 27.788918\n",
      "iteration 47 has an accuracy in the dtst of 0.84 27.736519\n",
      "iteration 47 has an accuracy in the dtrn of 0.8483333333333334 27.736519\n",
      "iteration 48 has an accuracy in the dtst of 0.84 27.685375\n",
      "iteration 48 has an accuracy in the dtrn of 0.85 27.685375\n",
      "iteration 49 has an accuracy in the dtst of 0.84 27.635431\n",
      "iteration 49 has an accuracy in the dtrn of 0.8533333333333334 27.635431\n",
      "iteration 50 has an accuracy in the dtst of 0.84 27.586636\n",
      "iteration 50 has an accuracy in the dtrn of 0.855 27.586636\n",
      "iteration 51 has an accuracy in the dtst of 0.83 27.538944\n",
      "iteration 51 has an accuracy in the dtrn of 0.8533333333333334 27.538944\n",
      "iteration 52 has an accuracy in the dtst of 0.83 27.49231\n",
      "iteration 52 has an accuracy in the dtrn of 0.8566666666666667 27.49231\n",
      "iteration 53 has an accuracy in the dtst of 0.82 27.44669\n",
      "iteration 53 has an accuracy in the dtrn of 0.855 27.44669\n",
      "iteration 54 has an accuracy in the dtst of 0.82 27.402046\n",
      "iteration 54 has an accuracy in the dtrn of 0.8583333333333333 27.402046\n",
      "iteration 55 has an accuracy in the dtst of 0.82 27.358341\n",
      "iteration 55 has an accuracy in the dtrn of 0.8566666666666667 27.358341\n",
      "iteration 56 has an accuracy in the dtst of 0.81 27.315538\n",
      "iteration 56 has an accuracy in the dtrn of 0.8566666666666667 27.315538\n",
      "iteration 57 has an accuracy in the dtst of 0.81 27.273605\n",
      "iteration 57 has an accuracy in the dtrn of 0.8616666666666667 27.273605\n",
      "iteration 58 has an accuracy in the dtst of 0.81 27.23251\n",
      "iteration 58 has an accuracy in the dtrn of 0.8616666666666667 27.23251\n",
      "iteration 59 has an accuracy in the dtst of 0.81 27.19222\n",
      "iteration 59 has an accuracy in the dtrn of 0.8633333333333333 27.19222\n",
      "iteration 60 has an accuracy in the dtst of 0.81 27.152712\n",
      "iteration 60 has an accuracy in the dtrn of 0.865 27.152712\n",
      "iteration 61 has an accuracy in the dtst of 0.81 27.113953\n",
      "iteration 61 has an accuracy in the dtrn of 0.865 27.113953\n",
      "iteration 62 has an accuracy in the dtst of 0.81 27.07592\n",
      "iteration 62 has an accuracy in the dtrn of 0.8633333333333333 27.07592\n",
      "iteration 63 has an accuracy in the dtst of 0.81 27.03859\n",
      "iteration 63 has an accuracy in the dtrn of 0.8633333333333333 27.03859\n",
      "iteration 64 has an accuracy in the dtst of 0.81 27.001938\n",
      "iteration 64 has an accuracy in the dtrn of 0.8633333333333333 27.001938\n",
      "iteration 65 has an accuracy in the dtst of 0.81 26.965942\n",
      "iteration 65 has an accuracy in the dtrn of 0.8633333333333333 26.965942\n",
      "iteration 66 has an accuracy in the dtst of 0.81 26.93058\n",
      "iteration 66 has an accuracy in the dtrn of 0.8633333333333333 26.93058\n",
      "iteration 67 has an accuracy in the dtst of 0.81 26.895834\n",
      "iteration 67 has an accuracy in the dtrn of 0.8633333333333333 26.895834\n",
      "iteration 68 has an accuracy in the dtst of 0.81 26.861683\n",
      "iteration 68 has an accuracy in the dtrn of 0.8633333333333333 26.861683\n",
      "iteration 69 has an accuracy in the dtst of 0.82 26.828108\n",
      "iteration 69 has an accuracy in the dtrn of 0.8633333333333333 26.828108\n",
      "iteration 70 has an accuracy in the dtst of 0.82 26.795094\n",
      "iteration 70 has an accuracy in the dtrn of 0.8633333333333333 26.795094\n",
      "iteration 71 has an accuracy in the dtst of 0.82 26.762623\n",
      "iteration 71 has an accuracy in the dtrn of 0.8633333333333333 26.762623\n",
      "iteration 72 has an accuracy in the dtst of 0.82 26.730677\n",
      "iteration 72 has an accuracy in the dtrn of 0.8633333333333333 26.730677\n",
      "iteration 73 has an accuracy in the dtst of 0.82 26.699244\n",
      "iteration 73 has an accuracy in the dtrn of 0.8633333333333333 26.699244\n",
      "iteration 74 has an accuracy in the dtst of 0.82 26.668306\n",
      "iteration 74 has an accuracy in the dtrn of 0.8616666666666667 26.668306\n",
      "iteration 75 has an accuracy in the dtst of 0.82 26.63785\n",
      "iteration 75 has an accuracy in the dtrn of 0.8616666666666667 26.63785\n",
      "iteration 76 has an accuracy in the dtst of 0.82 26.607864\n",
      "iteration 76 has an accuracy in the dtrn of 0.865 26.607864\n",
      "iteration 77 has an accuracy in the dtst of 0.83 26.578333\n",
      "iteration 77 has an accuracy in the dtrn of 0.865 26.578333\n",
      "iteration 78 has an accuracy in the dtst of 0.83 26.549244\n",
      "iteration 78 has an accuracy in the dtrn of 0.865 26.549244\n",
      "iteration 79 has an accuracy in the dtst of 0.83 26.520588\n",
      "iteration 79 has an accuracy in the dtrn of 0.865 26.520588\n",
      "iteration 80 has an accuracy in the dtst of 0.83 26.49235\n",
      "iteration 80 has an accuracy in the dtrn of 0.8666666666666667 26.49235\n",
      "iteration 81 has an accuracy in the dtst of 0.83 26.464521\n",
      "iteration 81 has an accuracy in the dtrn of 0.865 26.464521\n",
      "iteration 82 has an accuracy in the dtst of 0.83 26.43709\n",
      "iteration 82 has an accuracy in the dtrn of 0.865 26.43709\n",
      "iteration 83 has an accuracy in the dtst of 0.83 26.410048\n",
      "iteration 83 has an accuracy in the dtrn of 0.865 26.410048\n",
      "iteration 84 has an accuracy in the dtst of 0.83 26.38338\n",
      "iteration 84 has an accuracy in the dtrn of 0.865 26.38338\n",
      "iteration 85 has an accuracy in the dtst of 0.83 26.357082\n",
      "iteration 85 has an accuracy in the dtrn of 0.865 26.357082\n",
      "iteration 86 has an accuracy in the dtst of 0.83 26.331142\n",
      "iteration 86 has an accuracy in the dtrn of 0.8666666666666667 26.331142\n",
      "iteration 87 has an accuracy in the dtst of 0.83 26.305552\n",
      "iteration 87 has an accuracy in the dtrn of 0.8666666666666667 26.305552\n",
      "iteration 88 has an accuracy in the dtst of 0.83 26.280304\n",
      "iteration 88 has an accuracy in the dtrn of 0.865 26.280304\n",
      "iteration 89 has an accuracy in the dtst of 0.83 26.255388\n",
      "iteration 89 has an accuracy in the dtrn of 0.865 26.255388\n",
      "iteration 90 has an accuracy in the dtst of 0.83 26.230799\n",
      "iteration 90 has an accuracy in the dtrn of 0.865 26.230799\n",
      "iteration 91 has an accuracy in the dtst of 0.83 26.206526\n",
      "iteration 91 has an accuracy in the dtrn of 0.865 26.206526\n",
      "iteration 92 has an accuracy in the dtst of 0.83 26.182562\n",
      "iteration 92 has an accuracy in the dtrn of 0.865 26.182562\n",
      "iteration 93 has an accuracy in the dtst of 0.83 26.158901\n",
      "iteration 93 has an accuracy in the dtrn of 0.865 26.158901\n",
      "iteration 94 has an accuracy in the dtst of 0.82 26.135536\n",
      "iteration 94 has an accuracy in the dtrn of 0.865 26.135536\n",
      "iteration 95 has an accuracy in the dtst of 0.82 26.112461\n",
      "iteration 95 has an accuracy in the dtrn of 0.8633333333333333 26.112461\n",
      "iteration 96 has an accuracy in the dtst of 0.82 26.089666\n",
      "iteration 96 has an accuracy in the dtrn of 0.865 26.089666\n",
      "iteration 97 has an accuracy in the dtst of 0.82 26.06715\n",
      "iteration 97 has an accuracy in the dtrn of 0.865 26.06715\n",
      "iteration 98 has an accuracy in the dtst of 0.82 26.044903\n",
      "iteration 98 has an accuracy in the dtrn of 0.865 26.044903\n",
      "iteration 99 has an accuracy in the dtst of 0.82 26.022919\n",
      "iteration 99 has an accuracy in the dtrn of 0.865 26.022919\n",
      "iteration 100 has an accuracy in the dtst of 0.82 26.001196\n",
      "iteration 100 has an accuracy in the dtrn of 0.865 26.001196\n"
     ]
    }
   ],
   "source": [
    "println(\"Adaline with batch size of 100\")\n",
    "wAdaline_1 = train(adaline, xtrn, ytrn, 20)\n",
    "println(\"Adaline with batch size of 1\")\n",
    "wAdaline_100 = train(adaline, dtrn, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softMax (generic function with 2 methods)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softMax(w, x, y, lr = 0.000001)\n",
    "    probs = exp.(w*x)\n",
    "    println(summary(probs))\n",
    "    probs ./= sum(probs)\n",
    "    err = props - y\n",
    "    w .-= lr * err * x'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftMax with batch size of 100\n",
      "10×1 Array{Float32,2}\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: props not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: props not defined",
      "",
      "Stacktrace:",
      " [1] softMax(::Array{Float32,2}, ::Array{Float32,2}, ::Array{Float64,2}, ::Float64) at ./In[50]:5",
      " [2] softMax at ./In[50]:2 [inlined]",
      " [3] train(::typeof(softMax), ::Array{Float32,2}, ::Array{Float64,2}, ::Int64) at ./In[45]:7",
      " [4] top-level scope at In[51]:2"
     ]
    }
   ],
   "source": [
    "println(\"SoftMax with batch size of 100\")\n",
    "wSoftmax_1 = train(softMax, xtrn, ytrn, 20)\n",
    "println(\"SoftMax with batch size of 1\")\n",
    "wSoftmax_100 = train(softMax, dtrn, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimize (generic function with 2 methods)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optemize with an array data set\n",
    "#define argmax and max for Knet types\n",
    "Base.argmax(a::KnetArray) = argmax(Array(a))\n",
    "Base.argmax(a::AutoGrad.Value) = argmax(value(a))\n",
    "Base.max(a::KnetArray) = max(Array(a))\n",
    "Base.max(a::AutoGrad.Value) = max(value(a))\n",
    "ARRAY = Array{Float32}\n",
    "function optimize(loss, x::Array , y::Array, iter; lr = 1e-4)\n",
    "    #specify that the elements of w are paprameters(meaning you want the gradient to be with respect to them)\n",
    "    w = Param(rand(Float64, (size(y,1), size(x,1))))\n",
    "    for i in 1:(1<<iter)\n",
    "        #choose a random data entry\n",
    "        ind = rand(1:size(x,2))\n",
    "        L = @diff loss(w, x[:,ind], y[:,ind])\n",
    "        ∇w = grad(L, w)\n",
    "        w .-= lr * ∇w\n",
    "        if log2(i) ≈ round(log2(i))\n",
    "            println(\"iteration $i has an accuracy in the dtst of $(accuracy(w,dtst))\", \" \", norm(w))\n",
    "            println(\"iteration $i has an accuracy in the dtrn of $(accuracy(w,dtrn))\", \" \", norm(w))\n",
    "        end\n",
    "    end\n",
    "    println(\"iteration $((1<<iter)) has an accuracy in the dtst of $(accuracy(w,dtst))\", \" \", norm(w))\n",
    "    println(\"iteration $((1<<iter))has an accuracy in the dtrn of $(accuracy(w,dtrn))\", \" \", norm(w))\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimize (generic function with 2 methods)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optemize with an array data set (batch size > 1)\n",
    "#define argmax and max for Knet types\n",
    "Base.argmax(a::KnetArray) = argmax(Array(a))\n",
    "Base.argmax(a::AutoGrad.Value) = argmax(value(a))\n",
    "Base.max(a::KnetArray) = max(Array(a))\n",
    "Base.max(a::AutoGrad.Value) = max(value(a))\n",
    "function optimize(loss, data, iter; lr = 1e-4)\n",
    "    #specify that the elements of w are paprameters(meaning you want the gradient to be with respect to them)\n",
    "    (x,y) = first(data)\n",
    "    w = Param(rand(Float64, (size(y,1), size(x,1))))\n",
    "    for i in 1:iter\n",
    "        for (x,y) in data\n",
    "            L = @diff loss(w,x,y)\n",
    "            ∇w = grad(L, w)\n",
    "            w .-= lr * ∇w\n",
    "        end\n",
    "        println(\"iteration $i has an accuracy in the dtst of $(accuracy(w,dtst))\", \" \", norm(w))\n",
    "        println(\"iteration $i has an accuracy in the dtrn of $(accuracy(w,dtrn))\", \" \", norm(w))\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron loss for Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perceptronLoss (generic function with 1 method)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function perceptronLoss(w, x, y)\n",
    "    ŷ = w * x\n",
    "    #println.(summary.([w,x,y,ŷ]))\n",
    "    return sum([ŷ[argmax(ŷ[:,i])] - ŷ[argmax(y[:,i])] for i in size(y,2)])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching optimize(::typeof(perceptronLoss), ::Array{Float32,2}, ::Array{Float64,2}, ::Int64, ::Int64)\nClosest candidates are:\n  optimize(::Any, ::Array, ::Array, ::Any; lr) at In[52]:10\n  optimize(::Any, ::Any, ::Any; lr) at In[53]:9",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching optimize(::typeof(perceptronLoss), ::Array{Float32,2}, ::Array{Float64,2}, ::Int64, ::Int64)\nClosest candidates are:\n  optimize(::Any, ::Array, ::Array, ::Any; lr) at In[52]:10\n  optimize(::Any, ::Any, ::Any; lr) at In[53]:9",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[55]:1"
     ]
    }
   ],
   "source": [
    "wperceptron2_1 = optimize(perceptronLoss, xtrn, ytrn,20,1)\n",
    "#wperceptron2_100 = optimize(perceptronLoss, dtrn, 100, lr = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adalineLoss (generic function with 1 method)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function adalineLoss(w, x, y)\n",
    "    0.5 * sum(abs2, w * x - y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 has an accuracy in the dtst of 0.17 50.745867950353315\n",
      "iteration 1 has an accuracy in the dtrn of 0.13 50.745867950353315\n",
      "iteration 2 has an accuracy in the dtst of 0.17 50.68811944592059\n",
      "iteration 2 has an accuracy in the dtrn of 0.13 50.68811944592059\n",
      "iteration 4 has an accuracy in the dtst of 0.17 50.606165993521756\n",
      "iteration 4 has an accuracy in the dtrn of 0.13 50.606165993521756\n",
      "iteration 8 has an accuracy in the dtst of 0.17 50.43935583456351\n",
      "iteration 8 has an accuracy in the dtrn of 0.13166666666666665 50.43935583456351\n",
      "iteration 16 has an accuracy in the dtst of 0.18 50.04487308609508\n",
      "iteration 16 has an accuracy in the dtrn of 0.13666666666666666 50.04487308609508\n",
      "iteration 32 has an accuracy in the dtst of 0.18 49.337826743453576\n",
      "iteration 32 has an accuracy in the dtrn of 0.135 49.337826743453576\n",
      "iteration 64 has an accuracy in the dtst of 0.19 47.87726528844851\n",
      "iteration 64 has an accuracy in the dtrn of 0.12333333333333334 47.87726528844851\n",
      "iteration 128 has an accuracy in the dtst of 0.19 45.692262758054355\n",
      "iteration 128 has an accuracy in the dtrn of 0.125 45.692262758054355\n",
      "iteration 256 has an accuracy in the dtst of 0.17 43.86171135649638\n",
      "iteration 256 has an accuracy in the dtrn of 0.11333333333333333 43.86171135649638\n",
      "iteration 512 has an accuracy in the dtst of 0.16 42.67551352793957\n",
      "iteration 512 has an accuracy in the dtrn of 0.105 42.67551352793957\n",
      "iteration 1024 has an accuracy in the dtst of 0.15 42.187896443962835\n",
      "iteration 1024 has an accuracy in the dtrn of 0.10833333333333334 42.187896443962835\n",
      "iteration 2048 has an accuracy in the dtst of 0.2 41.682296300103644\n",
      "iteration 2048 has an accuracy in the dtrn of 0.10166666666666667 41.682296300103644\n",
      "iteration 4096 has an accuracy in the dtst of 0.17 41.083434344117165\n",
      "iteration 4096 has an accuracy in the dtrn of 0.11333333333333333 41.083434344117165\n",
      "iteration 8192 has an accuracy in the dtst of 0.19 40.34666386648199\n",
      "iteration 8192 has an accuracy in the dtrn of 0.16 40.34666386648199\n",
      "iteration 16384 has an accuracy in the dtst of 0.25 39.480767429847894\n",
      "iteration 16384 has an accuracy in the dtrn of 0.21166666666666667 39.480767429847894\n",
      "iteration 32768 has an accuracy in the dtst of 0.27 38.47881160174713\n",
      "iteration 32768 has an accuracy in the dtrn of 0.25 38.47881160174713\n",
      "iteration 65536 has an accuracy in the dtst of 0.37 37.23547502530138\n",
      "iteration 65536 has an accuracy in the dtrn of 0.32166666666666666 37.23547502530138\n",
      "iteration 131072 has an accuracy in the dtst of 0.47 35.68101736471372\n",
      "iteration 131072 has an accuracy in the dtrn of 0.37166666666666665 35.68101736471372\n",
      "iteration 262144 has an accuracy in the dtst of 0.57 33.91926486718857\n",
      "iteration 262144 has an accuracy in the dtrn of 0.47833333333333333 33.91926486718857\n",
      "iteration 524288 has an accuracy in the dtst of 0.64 32.00557947079528\n",
      "iteration 524288 has an accuracy in the dtrn of 0.6216666666666667 32.00557947079528\n",
      "iteration 1048576 has an accuracy in the dtst of 0.78 30.125962059905476\n",
      "iteration 1048576 has an accuracy in the dtrn of 0.7616666666666667 30.125962059905476\n",
      "iteration 1048576 has an accuracy in the dtst of 0.78 30.125962059905476\n",
      "iteration 1048576has an accuracy in the dtrn of 0.7616666666666667 30.125962059905476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10×784 Param{Array{Float64,2}}:\n",
       " 0.0816785  0.783621  0.960462   …  0.221125  0.735183  0.303756 \n",
       " 0.340914   0.601813  0.618383      0.954401  0.487558  0.0985897\n",
       " 0.953995   0.998239  0.974222      0.994196  0.759583  0.352226 \n",
       " 0.822231   0.882142  0.0277838     0.329304  0.830696  0.316068 \n",
       " 0.107332   0.686416  0.746053      0.673593  0.609202  0.332677 \n",
       " 0.402705   0.285569  0.421953   …  0.987703  0.80308   0.945462 \n",
       " 0.8072     0.292022  0.591581      0.452785  0.949663  0.466681 \n",
       " 0.338049   0.86492   0.909467      0.207589  0.487584  0.0756507\n",
       " 0.868927   0.210251  0.255493      0.729173  0.989308  0.161727 \n",
       " 0.407418   0.628115  0.270307      0.981535  0.664248  0.987107 "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wadaline2_1 = optimize(adalineLoss, xtrn, ytrn, 20, lr = 1e-4)\n",
    "#wadaline2_100 = optimize(adalineLoss, dtrn, 100, lr = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoftMax loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmaxLoss (generic function with 1 method)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softmaxLoss(w, x, y)\n",
    "    probs = exp.(w*x)\n",
    "    probs /= sum(probs)\n",
    "    -log(probs[argmax(y)])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 has an accuracy in the dtst of 0.04 50.93879965718354\n",
      "iteration 1 has an accuracy in the dtrn of 0.035 50.93879965718354\n",
      "iteration 2 has an accuracy in the dtst of 0.11 50.94295849076033\n",
      "iteration 2 has an accuracy in the dtrn of 0.07666666666666666 50.94295849076033\n",
      "iteration 4 has an accuracy in the dtst of 0.1 50.95647378293378\n",
      "iteration 4 has an accuracy in the dtrn of 0.09833333333333333 50.95647378293378\n",
      "iteration 8 has an accuracy in the dtst of 0.23 50.96440036531267\n",
      "iteration 8 has an accuracy in the dtrn of 0.2 50.96440036531267\n",
      "iteration 16 has an accuracy in the dtst of 0.25 50.97645603976865\n",
      "iteration 16 has an accuracy in the dtrn of 0.26 50.97645603976865\n",
      "iteration 32 has an accuracy in the dtst of 0.36 51.03489649951219\n",
      "iteration 32 has an accuracy in the dtrn of 0.36833333333333335 51.03489649951219\n",
      "iteration 64 has an accuracy in the dtst of 0.41 51.14567632690647\n",
      "iteration 64 has an accuracy in the dtrn of 0.43166666666666664 51.14567632690647\n",
      "iteration 128 has an accuracy in the dtst of 0.65 51.361917982220234\n",
      "iteration 128 has an accuracy in the dtrn of 0.64 51.361917982220234\n",
      "iteration 256 has an accuracy in the dtst of 0.71 51.77579589797086\n",
      "iteration 256 has an accuracy in the dtrn of 0.7066666666666667 51.77579589797086\n",
      "iteration 512 has an accuracy in the dtst of 0.61 52.27201015963231\n",
      "iteration 512 has an accuracy in the dtrn of 0.66 52.27201015963231\n",
      "iteration 1024 has an accuracy in the dtst of 0.79 53.02243407656859\n",
      "iteration 1024 has an accuracy in the dtrn of 0.7266666666666667 53.02243407656859\n",
      "iteration 2048 has an accuracy in the dtst of 0.85 53.979171678704205\n",
      "iteration 2048 has an accuracy in the dtrn of 0.8533333333333334 53.979171678704205\n",
      "iteration 4096 has an accuracy in the dtst of 0.87 56.00494586470732\n",
      "iteration 4096 has an accuracy in the dtrn of 0.8733333333333333 56.00494586470732\n",
      "iteration 8192 has an accuracy in the dtst of 0.92 58.66872131762772\n",
      "iteration 8192 has an accuracy in the dtrn of 0.885 58.66872131762772\n",
      "iteration 16384 has an accuracy in the dtst of 0.9 61.93659840614257\n",
      "iteration 16384 has an accuracy in the dtrn of 0.88 61.93659840614257\n",
      "iteration 32768 has an accuracy in the dtst of 0.88 66.46199416034663\n",
      "iteration 32768 has an accuracy in the dtrn of 0.9166666666666666 66.46199416034663\n",
      "iteration 65536 has an accuracy in the dtst of 0.89 72.56822936786888\n",
      "iteration 65536 has an accuracy in the dtrn of 0.9166666666666666 72.56822936786888\n",
      "iteration 131072 has an accuracy in the dtst of 0.93 81.9013339991245\n",
      "iteration 131072 has an accuracy in the dtrn of 0.9216666666666666 81.9013339991245\n",
      "iteration 262144 has an accuracy in the dtst of 0.93 93.99009012015787\n",
      "iteration 262144 has an accuracy in the dtrn of 0.9216666666666666 93.99009012015787\n",
      "iteration 524288 has an accuracy in the dtst of 0.9 110.73000655062086\n",
      "iteration 524288 has an accuracy in the dtrn of 0.925 110.73000655062086\n",
      "iteration 1048576 has an accuracy in the dtst of 0.96 133.33853091582182\n",
      "iteration 1048576 has an accuracy in the dtrn of 0.9183333333333333 133.33853091582182\n",
      "iteration 1048576 has an accuracy in the dtst of 0.96 133.33853091582182\n",
      "iteration 1048576has an accuracy in the dtrn of 0.9183333333333333 133.33853091582182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10×784 Param{Array{Float64,2}}:\n",
       " 0.749103    0.272814  0.851808   …  0.557029   0.209648  0.0108601\n",
       " 0.997745    0.552424  0.59675       0.208948   0.682369  0.310333 \n",
       " 0.00569862  0.759072  0.338367      0.525343   0.798353  0.601278 \n",
       " 0.380038    0.76398   0.923227      0.397472   0.287898  0.151269 \n",
       " 0.736378    0.715742  0.743611      0.740885   0.358644  0.097799 \n",
       " 0.666178    0.389635  0.0817159  …  0.0219585  0.991534  0.729101 \n",
       " 0.847871    0.792097  0.887692      0.41466    0.931685  0.284926 \n",
       " 0.994637    0.250989  0.213864      0.668789   0.451981  0.0654324\n",
       " 0.945121    0.938058  0.75696       0.62484    0.16478   0.373944 \n",
       " 0.449751    0.745418  0.270957      0.820157   0.408198  0.303301 "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsoftmax2_1 = optimize(softmaxLoss, xtrn, ytrn, 20 , lr = 0.1)\n",
    "#wsoftmax2_100 = optimize(softmaxLoss, dtrn, 100, lr = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
