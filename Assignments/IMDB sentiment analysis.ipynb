{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "#haskey(Pkg.installed(), \"Languages\") || Pkg.add(\"Languages\")\n",
    "using Knet, Plots, Statistics, LinearAlgebra, Random\n",
    "using Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=Citation: Publications Using the Dataset. Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).=#\n",
    "DATA_URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "FILE_NAME = \"aclImdb\"\n",
    "DATA_DIR = \"./Data\"\n",
    "NGRAM = 5\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_extract_reviews (generic function with 2 methods)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a struct for a review that has a text (list of words)and a label\n",
    "struct review txt; label;end\n",
    "\n",
    "#download review from DARA_URL\n",
    "function _download_reviews()\n",
    "    if !isdir(DATA_DIR)\n",
    "        mkdir(DATA_DIR)\n",
    "    end\n",
    "    url = DATA_URL\n",
    "    path = \"$DATA_DIR/$FILE_NAME\"\n",
    "    if !isdir(path)\n",
    "        println(\"Downloading the data from the internet...\")\n",
    "        file = \"aclImdb_v1.tar\"\n",
    "        #file = download(url, path)\n",
    "        println(\"Extracting the data...\")\n",
    "        run(`tar -xvf $(joinpath(DATA_DIR, file)) -C ./DATA_DIR/ -C`)\n",
    "        println(\"Finished.\")\n",
    "        rm(file)\n",
    "    end\n",
    "    return path\n",
    "end\n",
    "\n",
    "#creat a dictionary of stopwords\n",
    "_stopwords = Dict(x => true for x in stopwords(Languages.English()))\n",
    "\n",
    "#clean a review by 1-removing punctionations and extra spaces, split into an array or words \n",
    "#removing stopwords, and covert ot lowercase. Then retern a list of words\n",
    "function clean_text(txt)\n",
    "    txt = replace(txt, r\"[^a-zA-Z\\s-]\" => \" \")\n",
    "    txt = replace(txt, r\"--\" => \" \")\n",
    "    txt = replace(txt, r\"\\s+\" => \" \")\n",
    "    lst = split(txt)\n",
    "    lst = map(lowercase, lst)\n",
    "    #&& get.(_stopwords) != true \n",
    "    lst = lst[[(length(i) > 2 && get(_stopwords, i, false) != true) for i in lst]]\n",
    "    return lst\n",
    "end\n",
    "\n",
    "#extract review from the files insided a specific directory, clean the data and return a list of reviews struct\n",
    "function _extract_reviews(path, label = 0)\n",
    "    content = []\n",
    "    for f in readdir(path)\n",
    "        open(string(path,\"/\",f)) do re\n",
    "            txt = read(re,String)\n",
    "            #println(txt)\n",
    "            push!(content, review(clean_text(txt), label))\n",
    "        end\n",
    "    end\n",
    "    return content\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an ngram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ngram (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ngram(lst, n)\n",
    "    new_lst = copy(lst)\n",
    "    for i in 2:min(n,length(lst))\n",
    "        for j in i:length(lst)\n",
    "            push!(new_lst, join(lst[j-i+1:j], \"_\"))\n",
    "        end\n",
    "    end\n",
    "    return new_lst\n",
    "end\n",
    "#proccess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Naive Bayes model\n",
    "struct NaiveBayes2 class_prob; map_prob; end\n",
    "\n",
    "#map words into numbers and calcualte the frequency\n",
    "function map_word(dtrn)\n",
    "    w2n = Dict()\n",
    "    n2w = Dict()\n",
    "    t = 1\n",
    "    words_cnt = Dict()\n",
    "    for re in dtrn\n",
    "        lst = re.txt\n",
    "        lbl = re.label\n",
    "        for word in lst\n",
    "            if !haskey(words_cnt, word)\n",
    "                get!(w2n, word, t)\n",
    "                get!(n2w, t, word)\n",
    "                get!(words_cnt, word, fill(0, length(c2i)))\n",
    "            end\n",
    "            words_cnt[word][lbl] += 1\n",
    "        end\n",
    "    end\n",
    "    words_cnt, w2n ,n2w\n",
    "end\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define predict function\n",
    "function predict(txt, nb, eps = 10)\n",
    "    prob = [log(nb.class_prob[c]) + sum([log(haskey(nb.map_prob, w) ? nb.map_prob[w][c]+eps : eps) for w in txt]) for c in 1:length(c2i)]\n",
    "    ind = argmax(prob)\n",
    "    #println(\"Model prediction is $(i2c[ind])\")\n",
    "    return ind\n",
    "end\n",
    "predict(txt::String, nb) = predict(txt)\n",
    "\n",
    "#define accuracy function\n",
    "function accuracy(dtst, nb)\n",
    "    return mean([re.label == predict(re.txt, nb) for re in dtst])\n",
    "end\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks for different NGRAMS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data..\n",
      "Extracting data..\n",
      "Finsied extracting and cleaning 25000 training reviews and 25000 testing reviews\n"
     ]
    }
   ],
   "source": [
    "println(\"Downloading data..\")\n",
    "path = _download_reviews()\n",
    "println(\"Extracting data..\")\n",
    "c2i = Dict(\"Positive\" => 1, \"Negative\" => 2)\n",
    "i2c = Dict(1 => \"Positive\", 2 => \"Negative\")\n",
    "dtrn = [_extract_reviews(joinpath(path, \"train\", \"pos\"), 1); _extract_reviews(joinpath(path, \"train\", \"neg\"), 2)]\n",
    "dtst = [_extract_reviews(joinpath(path, \"test\", \"pos\"), 1); _extract_reviews(joinpath(path, \"test\", \"neg\"), 2)]\n",
    "println(\"Finsied extracting and cleaning $(length(dtrn)) training reviews and $(length(dtrn)) testing reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling data in 1 gram model\n",
      "Naive Bayes model with 1 gram model prodcued accuracy of 0.8342\n",
      "modeling data in 2 gram model\n",
      "Naive Bayes model with 2 gram model prodcued accuracy of 0.84492\n",
      "modeling data in 3 gram model\n",
      "Naive Bayes model with 3 gram model prodcued accuracy of 0.84588\n",
      "modeling data in 4 gram model\n",
      "Naive Bayes model with 4 gram model prodcued accuracy of 0.84584\n",
      "modeling data in 5 gram model\n",
      "Naive Bayes model with 5 gram model prodcued accuracy of 0.8458\n",
      "modeling data in 6 gram model\n",
      "Naive Bayes model with 6 gram model prodcued accuracy of 0.8458\n"
     ]
    }
   ],
   "source": [
    "for i in 1:6\n",
    "    println(\"modeling data in $i gram model\")\n",
    "    dtrn2 = [review(ngram(re.txt, i),re.label) for re in dtrn]\n",
    "    dtst2 = [review(ngram(re.txt, i),re.label) for re in dtst]\n",
    "    words_cnt, w2n ,n2w = map_word(dtrn2)\n",
    "    #find class probability\n",
    "    c_p = [sum([re.label == c for re in dtrn]) for c in 1:length(c2i)]\n",
    "    println(\"Naive Bayes model with $i gram model prodcued accuracy of $(accuracy(dtst2, NaiveBayes2(c_p, words_cnt)))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
